{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.chdir(\"..\")\n",
    "from data.dataset import ConditionalDataset\n",
    "from data.utils import to_one_hot, load_asd_score, load_dfnc, vector2matrix, compute_sub_per_state, compute_fnc_per_state, compute_dwell_state, compute_transition_matrix, find_unique_ind\n",
    "from models.vae import VAE\n",
    "from models.ivae import iVAE\n",
    "from models.utils import EarlyStopper\n",
    "from visualization.utils import plot_fnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set VAE parameters\n",
    "method = 'vae'\n",
    "seed = 9\n",
    "n_layer = 5\n",
    "hidden_dim = [256, 128, 64, 32, 16]\n",
    "latent_dim = 2\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "n_epoch = 1000\n",
    "cuda = False\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "res_path = f'/data/users4/xli/interpolation/results/dfnc_asd/{method}/test'\n",
    "os.mkdir(res_path) if not os.path.exists(res_path) else None\n",
    "ckpt_file = os.path.join(res_path, f'{method}_layer{n_layer}_dim{hidden_dim}_bs{batch_size}_lr{learning_rate}_seed{seed}.pt')\n",
    "\n",
    "# load subject measures and dFNC data\n",
    "data_path = '/data/users2/zfu/Matlab/GSU/Neuromark/Results'\n",
    "abide1_sub_path = os.path.join(data_path, 'Subject_selection', 'ABIDE1', 'sub_info_ABIDE1_TRall.mat')\n",
    "abide1_sub_data, abide1_site, invalid_sub_ind = load_asd_score(abide1_sub_path)\n",
    "abide1_dfnc_path = os.path.join(data_path, 'DFNC', 'ABIDE1', 'TRall', 'ABIDE1_dfnc_sub_*_sess_001_results.mat')\n",
    "abide1_dfnc_data = load_dfnc(abide1_dfnc_path, invalid_sub_ind, dataset='ABIDE')\n",
    "\n",
    "# concatenate patients and controls\n",
    "n_sub = 266\n",
    "ind_pt = np.where(((abide1_site==\"NYU\") | (abide1_site==\"UCLA_1\") | (abide1_site==\"USM\")) & (abide1_sub_data[:,0]==1))[0][:n_sub//2]\n",
    "ind_hc = np.where(((abide1_site==\"NYU\") | (abide1_site==\"UCLA_1\") | (abide1_site==\"USM\")) & (abide1_sub_data[:,0]==2))[0][:n_sub-len(ind_pt)]\n",
    "print(f\"N patient = {ind_pt.shape[0]}; N control = {ind_hc.shape[0]}\")\n",
    "\n",
    "sfnc_data = np.concatenate((abide1_dfnc_data[ind_pt, :], abide1_dfnc_data[ind_hc, :]), axis=0)\n",
    "sub_data = np.concatenate((abide1_sub_data[ind_pt, :], abide1_sub_data[ind_hc, :]), axis=0)\n",
    "age_pt = abide1_sub_data[ind_pt, -2]\n",
    "age_hc = abide1_sub_data[ind_hc, -2]\n",
    "sex_pt = abide1_sub_data[ind_pt, -1]\n",
    "sex_hc = abide1_sub_data[ind_hc, -1]\n",
    "# print(f\"Age patient mean={np.mean(age_pt):.2f}, std={np.std(age_pt):.2f}, max={max(age_pt):.0f}, min={min(age_pt):.0f}; control mean={np.mean(age_hc):.2f}, std={np.std(age_hc):.2f}, max={max(age_hc):.0f}, min={min(age_hc):.0f}\")\n",
    "# print(f\"Sex patient N male = {np.sum(sex_pt==1)}, N female = {np.sum(sex_pt==2)}; control N male = {np.sum(sex_hc==1)}, N female = {np.sum(sex_hc==2)}\")\n",
    "\n",
    "n_test = 41\n",
    "n_pt_test = n_test//2\n",
    "n_hc_test = n_test - n_pt_test\n",
    "ind_pt_test = []\n",
    "ind_hc_test = []\n",
    "site_patient = abide1_site[ind_pt]\n",
    "site_control = abide1_site[ind_hc]\n",
    "site_patient_list = list(np.unique(abide1_site[ind_pt]))\n",
    "site_control_list = list(np.unique(abide1_site[ind_hc]))\n",
    "\n",
    "# print(\"Patient\")\n",
    "for i, s in enumerate(site_patient_list):\n",
    "    ind = np.where(site_patient == s)[0]\n",
    "    # stratify test set by site\n",
    "    n_start = ind[0]\n",
    "    n_end = int(np.round(len(ind)/len(ind_pt)*n_test*0.5))\n",
    "    ind_pt_site_test = ind_pt[n_start:n_start+n_end]\n",
    "    ind_pt_test += list(ind_pt_site_test)\n",
    "    # print(f\"{s} & {len(ind)} & {np.sum(sex_pt[ind]==1)} & {np.sum(sex_pt[ind]==2)} & ${round(np.mean(age_pt[ind]), 2)}\\\\pm{round(np.std(age_pt[ind]),2)}$ & ${round(np.min(age_pt[ind]),2)}-{round(np.max(age_pt[ind]),2)}$\")\n",
    "\n",
    "# print(\"Control\")\n",
    "for i, s in enumerate(site_control_list):\n",
    "    ind = np.where(site_control == s)[0]\n",
    "    # stratify test set by site\n",
    "    n_start = ind[0]\n",
    "    n_end = int(np.round(len(ind)/len(ind_hc)*n_test*0.5))\n",
    "    if s==\"NYU\":\n",
    "        n_end += 1\n",
    "    ind_hc_site_test = ind_hc[n_start:n_start+n_end]\n",
    "    ind_hc_test += list(ind_hc_site_test)\n",
    "    # print(f\"{s} & {len(ind)} & {np.sum(sex_hc[ind]==1)} & {np.sum(sex_hc[ind]==2)} & ${round(np.mean(age_hc[ind]), 2)}\\\\pm{round(np.std(age_hc[ind]),2)}$ & ${round(np.min(age_hc[ind]),2)}-{round(np.max(age_hc[ind]),2)}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test sets\n",
    "n_train = n_sub - n_test\n",
    "ind_pt_train = list(set(ind_pt) - set(ind_pt_test))\n",
    "ind_hc_train = list(set(ind_hc) - set(ind_hc_test))\n",
    "n_pt_train = len(ind_pt_train)\n",
    "n_hc_train = len(ind_hc_train)\n",
    "n_pt_test = len(ind_pt_test)\n",
    "n_hc_test = len(ind_hc_test)\n",
    "print(f\"N patient test = {len(ind_pt_test)}; N control test = {len(ind_hc_test)}; N patient train = {len(ind_pt_train)}; N control train = {len(ind_hc_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnc_data_test = np.concatenate((abide1_dfnc_data[ind_pt_test, :, :], abide1_dfnc_data[ind_hc_test, :, :]), axis=0)\n",
    "sub_data_test = np.concatenate((abide1_sub_data[ind_pt_test, :], abide1_sub_data[ind_hc_test, :]), axis=0)\n",
    "dfnc_data_train = np.concatenate((abide1_dfnc_data[ind_pt_train, :], abide1_dfnc_data[ind_hc_train, :]), axis=0)\n",
    "sub_data_train = np.concatenate((abide1_sub_data[ind_pt_train, :], abide1_sub_data[ind_hc_train, :]), axis=0)\n",
    "\n",
    "n_window = dfnc_data_test.shape[1]\n",
    "n_feature = dfnc_data_test.shape[2]  \n",
    "print(f\"n_window = {n_window}; n_feature = {n_feature}\")\n",
    "\n",
    "dfnc_data_test_2d = dfnc_data_test.reshape((n_test*n_window, n_feature))\n",
    "dfnc_data_train_2d = dfnc_data_train.reshape((n_train*n_window, n_feature))\n",
    "\n",
    "y_test = to_one_hot(np.array([1]*n_pt_test*n_window+[2]*n_hc_test*n_window))[0][:,1:]\n",
    "y_train = to_one_hot(np.array([1]*n_pt_train*n_window+[2]*n_hc_train*n_window))[0][:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_list = []\n",
    "loss_l1_list = []\n",
    "loss_l2_list = []\n",
    "cluster_center_list = []\n",
    "label_list = []\n",
    "all_state_list = []\n",
    "\n",
    "for nc in range(2,10):\n",
    "    kmeans = KMeans(n_clusters=nc, random_state=0).fit(dfnc_data_train_2d)\n",
    "    kmeans_list.append(kmeans)\n",
    "    cluster_center = kmeans.cluster_centers_\n",
    "    cluster_center_list.append(cluster_center)\n",
    "    label = kmeans.labels_\n",
    "    label_list.append(label)\n",
    "\n",
    "    # K-means states\n",
    "    state_list = []\n",
    "    for i in range(nc):\n",
    "        state = vector2matrix(cluster_center[i])\n",
    "        state_list.append(state)\n",
    "    all_state_list.append(state_list)\n",
    "\n",
    "    loss_l1, loss_l2 = 0, 0\n",
    "    for i, l in enumerate(label):\n",
    "        loss_l1 += np.sum(np.abs(cluster_center[l]-dfnc_data_train_2d[i,:])) # L1 norm\n",
    "        loss_l2 += np.sum((cluster_center[l]-dfnc_data_train_2d[i,:])**2) # L2 norm\n",
    "    loss_l1 /= n_train*n_window\n",
    "    loss_l2 /= n_train*n_window\n",
    "    loss_l1_list.append(loss_l1)\n",
    "    loss_l2_list.append(loss_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10,3))\n",
    "axes[0].plot(range(2,10), loss_l1_list)\n",
    "axes[0].set_xlabel(\"k\", fontsize=12)\n",
    "axes[0].set_ylabel(\"L1 loss\", fontsize=12)\n",
    "axes[1].plot(range(2,10), loss_l2_list)\n",
    "axes[1].set_xlabel(\"k\", fontsize=12)\n",
    "axes[1].set_ylabel(\"L2 loss\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, 'dfnc_kmeans_loss.png'), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state = 5 # state 5\n",
    "\n",
    "# np.save(os.path.join(res_path, 'loss_l1_list.npy'), loss_l1_list)\n",
    "# np.save(os.path.join(res_path, 'loss_l2_list.npy'), loss_l2_list)\n",
    "# np.save(os.path.join(res_path, f'label_state{n_state}.npy'), label_list[n_state-2])\n",
    "# np.save(os.path.join(res_path, f'cluster_center_state{n_state}.npy'), cluster_center_list[n_state-2])\n",
    "# np.save(os.path.join(res_path, f'all_state_state{n_state}.npy'), all_state_list[n_state-2])\n",
    "\n",
    "kmeans_state = all_state_list[n_state-2]\n",
    "kmeans_label = label_list[n_state-2]\n",
    "kmeans_cluster_center = cluster_center_list[n_state-2]\n",
    "\n",
    "label_pt = kmeans_label[:n_pt_train*n_window]\n",
    "label_hc = kmeans_label[n_pt_train*n_window:]\n",
    "dfnc_data_train_2d_pt = dfnc_data_train_2d[:n_pt_train*n_window,:]\n",
    "dfnc_data_train_2d_hc = dfnc_data_train_2d[n_pt_train*n_window:,:]\n",
    "\n",
    "num_sub_per_state, ratio_sub_per_state = compute_sub_per_state(kmeans_label=kmeans_label, n_pt=n_pt_train, n_window=n_window)\n",
    "num_fnc_per_state, ratio_fnc_per_state = compute_fnc_per_state(kmeans_label=kmeans_label, n_pt=n_pt_train, n_window=n_window)\n",
    "sorted_state_ind = np.argsort(ratio_fnc_per_state[1,:])\n",
    "ratio_fnc_per_state_sorted = ratio_fnc_per_state[:, sorted_state_ind]\n",
    "\n",
    "print(num_sub_per_state)\n",
    "print(ratio_sub_per_state)\n",
    "print(num_fnc_per_state)\n",
    "print(ratio_fnc_per_state)\n",
    "print(sorted_state_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnc_state = np.zeros((3, n_state, 53, 53))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=n_state, figsize=(5*n_state, 5*3))\n",
    "\n",
    "for i, j in enumerate(np.arange(n_state)[sorted_state_ind]):\n",
    "  state_pt = dfnc_data_train_2d_pt[np.where(label_pt == j)[0],:]\n",
    "  state_hc = dfnc_data_train_2d_hc[np.where(label_hc == j)[0],:]\n",
    "  stat, pvalue = stats.ttest_ind(a=state_pt, b=state_hc, equal_var=True)\n",
    "  pvalue_map = vector2matrix(pvalue)\n",
    "  pvalue_mask = pvalue_map <= (0.05/len(pvalue))\n",
    "  upper_triangle_mask = np.triu(np.ones_like(pvalue_mask)).astype(bool)\n",
    "  pvalue_mask[upper_triangle_mask] = 1\n",
    "  cluster_median_1d_pt = np.median(state_pt, axis=0)\n",
    "  cluster_median_1d_hc = np.median(state_hc, axis=0)\n",
    "  dfnc_state[0,i] = vector2matrix(cluster_median_1d_pt)\n",
    "  dfnc_state[1,i] = vector2matrix(cluster_median_1d_hc)\n",
    "  dfnc_state[2,i] = dfnc_state[0,i] - dfnc_state[1,i]\n",
    "  if i == 0:\n",
    "    show_xticks = True\n",
    "  else:\n",
    "    show_xticks = False\n",
    "  plot_fnc(dfnc_state[0,i], axes[0,i], f\"{round(ratio_fnc_per_state_sorted[0,i]*100,1)}% ASD\\n{round(ratio_fnc_per_state_sorted[1,i]*100,1)}% CTR\", show_xticks=show_xticks)\n",
    "  plot_fnc(dfnc_state[1,i], axes[1,i], show_xticks=show_xticks)\n",
    "  plot_fnc(dfnc_state[2,i] * pvalue_mask * 2, axes[2,i], show_xticks=show_xticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, f'dfnc_kmeans_{n_state}states_pt_hc_pt-hc_sorted.png'), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(5*n_state, 5))\n",
    "\n",
    "for i, j in enumerate(np.arange(n_state)[sorted_state_ind]):\n",
    "  state = dfnc_data_train_2d[np.where(kmeans_label == j)[0], :]\n",
    "  state_median_1d = np.median(state, axis=0)\n",
    "  state_median_2d = vector2matrix(state_median_1d)\n",
    "  plot_fnc(state_median_2d, axes[i], f\"State {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, f'dfnc_kmeans_{n_state}states_pt_sorted.png'), bbox_inches='tight', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_time = num_fnc_per_state / num_sub_per_state\n",
    "dwell_time_sorted = dwell_time[:, sorted_state_ind]\n",
    "\n",
    "kmeans_label_2d = kmeans_label.reshape((n_train, n_window))\n",
    "dwell_state_mean_pt, dwell_state_ste_pt, dwell_state_mean_hc, dwell_state_ste_hc, dwell_state_pvalue = compute_dwell_state(kmeans_label_2d, sorted_state_ind, n_pt_train, n_hc_train)\n",
    "transition_matrix_pt, transition_matrix_hc, transition_matrix, transition_matrix_pvalue = compute_transition_matrix(kmeans_label_2d, sorted_state_ind, n_pt_train)\n",
    "\n",
    "np.save(os.path.join(res_path, 'dwell_time.npy'), dwell_time_sorted)\n",
    "np.save(os.path.join(res_path, 'dwell_state_pvalue.npy'), dwell_state_pvalue)\n",
    "np.save(os.path.join(res_path, 'dwell_state_mean_pt.npy'), dwell_state_mean_pt)\n",
    "np.save(os.path.join(res_path, 'dwell_state_ste_pt.npy'), dwell_state_ste_pt)\n",
    "np.save(os.path.join(res_path, 'dwell_state_mean_hc.npy'), dwell_state_mean_hc)\n",
    "np.save(os.path.join(res_path, 'dwell_state_ste_hc.npy'), dwell_state_ste_hc)\n",
    "np.save(os.path.join(res_path, 'transition_matrix_pt.npy'), transition_matrix_pt)\n",
    "np.save(os.path.join(res_path, 'transition_matrix_hc.npy'), transition_matrix_hc)\n",
    "np.save(os.path.join(res_path, 'transition_matrix.npy'), transition_matrix)\n",
    "np.save(os.path.join(res_path, 'transition_matrix_pvalue.npy'), transition_matrix_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = kmeans_list[n_state-2]\n",
    "kmeans_label_test = kmeans.predict(dfnc_data_test_2d)\n",
    "label_pt_test = kmeans_label_test[:n_pt_test*n_window]\n",
    "label_hc_test = kmeans_label_test[n_pt_test*n_window:]\n",
    "dfnc_data_test_2d_pt = dfnc_data_test_2d[:n_pt_test*n_window,:]\n",
    "dfnc_data_test_2d_hc = dfnc_data_test_2d[n_pt_test*n_window:,:]\n",
    "\n",
    "num_sub_per_state_test, ratio_sub_per_state_test = compute_sub_per_state(kmeans_label=kmeans_label_test, n_pt=n_pt_test, n_window=n_window)\n",
    "num_fnc_per_state_test, ratio_fnc_per_state_test = compute_fnc_per_state(kmeans_label=kmeans_label_test, n_pt=n_pt_test, n_window=n_window)\n",
    "sorted_state_ind_test = np.argsort(ratio_fnc_per_state_test[1,:])\n",
    "ratio_fnc_per_state_sorted_test = ratio_fnc_per_state_test[:, sorted_state_ind_test]\n",
    "\n",
    "print(num_sub_per_state_test)\n",
    "print(ratio_sub_per_state_test)\n",
    "print(num_fnc_per_state_test)\n",
    "print(ratio_fnc_per_state_test)\n",
    "print(sorted_state_ind_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnc_state_test = np.zeros((3, n_state, 53, 53))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=n_state, figsize=(5*n_state, 5*3))\n",
    "\n",
    "for i, j in enumerate(np.arange(n_state)[sorted_state_ind_test]):\n",
    "  state_pt = dfnc_data_test_2d_pt[np.where(label_pt_test == j)[0],:]\n",
    "  state_hc = dfnc_data_test_2d_hc[np.where(label_hc_test == j)[0],:]\n",
    "  stat, pvalue = stats.ttest_ind(a=state_pt, b=state_hc, equal_var=True)\n",
    "  pvalue_map = vector2matrix(pvalue)\n",
    "  pvalue_mask = pvalue_map <= (0.05/len(pvalue))\n",
    "  upper_triangle_mask = np.triu(np.ones_like(pvalue_mask)).astype(bool)\n",
    "  pvalue_mask[upper_triangle_mask] = 1\n",
    "  cluster_median_1d_pt = np.median(state_pt, axis=0)\n",
    "  cluster_median_1d_hc = np.median(state_hc, axis=0)\n",
    "  dfnc_state_test[0,i] = vector2matrix(cluster_median_1d_pt)\n",
    "  dfnc_state_test[1,i] = vector2matrix(cluster_median_1d_hc)\n",
    "  dfnc_state_test[2,i] = dfnc_state_test[0,i] - dfnc_state_test[1,i]\n",
    "  if i == 0:\n",
    "    show_xticks = True\n",
    "  else:\n",
    "    show_xticks = False\n",
    "  plot_fnc(dfnc_state_test[0,i], axes[0,i], f\"{round(ratio_fnc_per_state_sorted_test[0,i]*100,1)}% ASD\\n{round(ratio_fnc_per_state_sorted_test[1,i]*100,1)}% CTR\", show_xticks=show_xticks)\n",
    "  plot_fnc(dfnc_state_test[1,i], axes[1,i], show_xticks=show_xticks)\n",
    "  plot_fnc(dfnc_state_test[2,i] * pvalue_mask * 2, axes[2,i], show_xticks=show_xticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, f'dfnc_kmeans_{n_state}states_pt_hc_pt-hc_sorted_test.png'), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_time_test = num_fnc_per_state_test / num_sub_per_state_test\n",
    "dwell_time_sorted_test = dwell_time_test[:, sorted_state_ind_test]\n",
    "kmeans_label_2d_test = kmeans_label_test.reshape((n_test, n_window))\n",
    "\n",
    "dwell_state_mean_pt_test, dwell_state_ste_pt_test, dwell_state_mean_hc_test, dwell_state_ste_hc_test, dwell_state_pvalue_test = compute_dwell_state(kmeans_label_2d_test, sorted_state_ind_test, n_pt_test, n_hc_test)\n",
    "transition_matrix_pt_test, transition_matrix_hc_test, transition_matrix_test, transition_matrix_pvalue_test = compute_transition_matrix(kmeans_label_2d_test, sorted_state_ind_test, n_pt_test)\n",
    "\n",
    "np.save(os.path.join(res_path, 'dwell_time_test.npy'), dwell_time_sorted_test)\n",
    "np.save(os.path.join(res_path, 'dwell_state_pvalue_test.npy'), dwell_state_pvalue_test)\n",
    "np.save(os.path.join(res_path, 'dwell_state_mean_pt_test.npy'), dwell_state_mean_pt_test)\n",
    "np.save(os.path.join(res_path, 'dwell_state_ste_pt_test.npy'), dwell_state_ste_pt_test)\n",
    "np.save(os.path.join(res_path, 'dwell_state_mean_hc_test.npy'), dwell_state_mean_hc_test)\n",
    "np.save(os.path.join(res_path, 'dwell_state_ste_hc_test.npy'), dwell_state_ste_hc_test)\n",
    "np.save(os.path.join(res_path, 'transition_matrix_pt_test.npy'), transition_matrix_pt_test)\n",
    "np.save(os.path.join(res_path, 'transition_matrix_hc_test.npy'), transition_matrix_hc_test)\n",
    "np.save(os.path.join(res_path, 'transition_matrix_test.npy'), transition_matrix_test)\n",
    "np.save(os.path.join(res_path, 'transition_matrix_pvalue_test.npy'), transition_matrix_pvalue_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = dfnc_data_train_2d.shape[1]\n",
    "aux_dim = y_train.shape[1]\n",
    "\n",
    "loader_params = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "ds_train = ConditionalDataset(dfnc_data_train_2d.astype(np.float32), y_train.astype(np.float32), device)\n",
    "data_loader_train = DataLoader(ds_train, shuffle=False, batch_size=batch_size, **loader_params)\n",
    "\n",
    "ds_test = ConditionalDataset(dfnc_data_test_2d.astype(np.float32), y_test.astype(np.float32), device)\n",
    "data_loader_test = DataLoader(ds_test, shuffle=False, batch_size=batch_size, **loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'vae':\n",
    "    model = VAE(input_dim=data_dim, \n",
    "                latent_dim=latent_dim, \n",
    "                hidden_dims=hidden_dim, \n",
    "                seed=seed)\n",
    "    print(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10)\n",
    "    early_stopper = EarlyStopper(patience=20, threshold=1e-2, min_delta=1e-3)\n",
    "\n",
    "    # train model\n",
    "    model.train()\n",
    "    for it in range(n_epoch):\n",
    "        loss_train = 0\n",
    "        for _, (x, _) in enumerate(data_loader_train):\n",
    "            x = x.view(x.size(0), -1).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_rec, mean, logvar = model(x)\n",
    "            loss = model.loss(x_rec, x, mean, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        loss_train /= len(data_loader_train)\n",
    "        scheduler.step(loss_train)\n",
    "        print(f'Epoch: {it}; Loss: {loss_train:.5f}')\n",
    "        if early_stopper.early_stop(loss_train):\n",
    "            print(f'Early stopping triggered!')\n",
    "            break\n",
    "\n",
    "    # save model checkpoint after training\n",
    "    torch.save(model.state_dict(), ckpt_file)\n",
    "    \n",
    "    x_train, u_train = ds_train.x, ds_train.y\n",
    "    x_test, u_test = ds_test.x, ds_test.y\n",
    "    _, z_train, _ = model(x_train)\n",
    "    _, z_test, _ = model(x_test)\n",
    "    z_train = z_train.detach().cpu().numpy()\n",
    "    z_test = z_test.detach().cpu().numpy()\n",
    "\n",
    "elif method == 'ivae':\n",
    "    model = iVAE(data_dim=data_dim,\n",
    "                latent_dim=latent_dim,\n",
    "                aux_dim=aux_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                n_layer=n_layer,\n",
    "                activation='xtanh',\n",
    "                device=device,\n",
    "                seed=seed)\n",
    "    print(model)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10)\n",
    "    early_stopper = EarlyStopper(patience=20, threshold=1e-2, min_delta=1e-3)\n",
    "\n",
    "    # train model\n",
    "    model.train()\n",
    "\n",
    "    for it in range(n_epoch):\n",
    "        loss_train = 0\n",
    "        for _, (x, u) in enumerate(data_loader_train):\n",
    "            optimizer.zero_grad()\n",
    "            x, u = x.to(device), u.to(device)\n",
    "            loss, z_est = model.loss(x, u)\n",
    "            loss.mul(-1).backward()\n",
    "            optimizer.step()\n",
    "            loss_train += -loss.item()\n",
    "        loss_train /= len(data_loader_train)\n",
    "        scheduler.step(loss_train)\n",
    "        print(f'Epoch: {it}; Loss: {loss_train:.3f}')\n",
    "        if early_stopper.early_stop(loss_train):\n",
    "            print(f'Early stopping triggered!')\n",
    "            break\n",
    "\n",
    "    # save model checkpoint after training\n",
    "    torch.save(model.state_dict(), ckpt_file)\n",
    "\n",
    "    x_train, u_train = ds_train.x, ds_train.y\n",
    "    x_test, u_test = ds_test.x, ds_test.y\n",
    "    _, _, z_train, _ = model(x_train, u_train)\n",
    "    _, _, z_test, _ = model(x_test, u_test)\n",
    "    z_train = z_train.detach().cpu().numpy()\n",
    "    z_test = z_test.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_ms = 120\n",
    "cols = plt.cm.Oranges(np.linspace(0,1,n_window))\n",
    "for i in range(n_pt_train-1):\n",
    "  cols = np.concatenate([cols, plt.cm.Oranges(np.linspace(0,1,n_window))])\n",
    "for i in range(n_hc_train):\n",
    "  cols = np.concatenate([cols, plt.cm.Blues(np.linspace(0,1,n_window))])\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.scatter(z_train[:, 0], z_train[:, 1], marker='o', c=cols, s=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, 'vae_latent_space_train.png'), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = np.max(np.abs(z_train))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.scatter(z_train[:n_pt_train*n_window, 0], z_train[:n_pt_train*n_window, 1], marker='o', c=cols[:n_pt_train*n_window], s=1)\n",
    "plt.xlim([-lim, lim])\n",
    "plt.ylim([-lim, lim])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.scatter(z_train[n_pt_train*n_window:, 0], z_train[n_pt_train*n_window:, 1], marker='o', c=cols[n_pt_train*n_window:], s=1)\n",
    "plt.xlim([-lim, lim])\n",
    "plt.ylim([-lim, lim])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, 'vae_latent_space_train_pt_hc.png'), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_dfnc_data_train = np.zeros(dfnc_data_train_2d.shape)\n",
    "for i in range(dfnc_data_train_2d.shape[0]):\n",
    "  vae_z = torch.Tensor([[z_train[i,0], z_train[i,1]]])\n",
    "  vae_dfnc_data_train[i,:] = np.squeeze(model.decode(vae_z).detach().numpy())\n",
    "np.save(os.path.join(res_path, 'z_train.npy'), z_train)\n",
    "np.save(os.path.join(res_path, 'z_test.npy'), z_test)\n",
    "np.save(os.path.join(res_path, 'vae_dfnc_data_train.npy'), vae_dfnc_data_train)\n",
    "\n",
    "# z_train = np.load(os.path.join(res_path, 'z_train.npy'))\n",
    "# z_test = np.load(os.path.join(res_path, 'z_test.npy'))\n",
    "# vae_dfnc_data_train = np.load(os.path.join(res_path, 'vae_dfnc_data_train.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(input_dim=data_dim, \n",
    "            latent_dim=latent_dim, \n",
    "            hidden_dims=hidden_dim, \n",
    "            seed=seed)\n",
    "checkpoint = torch.load(ckpt_file, map_location=torch.device('cpu'), weights_only=False)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_kmeans_list = []\n",
    "vae_loss_l1_list = []\n",
    "vae_loss_l2_list = []\n",
    "vae_cluster_center_list = []\n",
    "vae_label_list = []\n",
    "vae_all_state_list = []\n",
    "\n",
    "for nc in range(2,10):\n",
    "  vae_kmeans = KMeans(n_clusters=nc, random_state=0).fit(z_train)\n",
    "  vae_kmeans_list.append(vae_kmeans)\n",
    "  vae_cluster_center = vae_kmeans.cluster_centers_\n",
    "  vae_cluster_center_list.append(vae_cluster_center)\n",
    "  vae_label = vae_kmeans.labels_\n",
    "  vae_label_list.append(vae_label)\n",
    "\n",
    "  # K-means states\n",
    "  state_list = []\n",
    "  for i in range(nc):\n",
    "    vae_z = torch.Tensor([[vae_cluster_center[i,0], vae_cluster_center[i,1]]])\n",
    "    x_reconstructed = np.squeeze(model.decode(vae_z).detach().numpy())\n",
    "    state = vector2matrix(x_reconstructed)\n",
    "    state_list.append(state)\n",
    "  vae_all_state_list.append(state_list)\n",
    "\n",
    "  loss_l1, loss_l2 = 0, 0\n",
    "  for i in range(len(vae_label)):\n",
    "    loss_l1 += np.sum(np.abs(vae_cluster_center[vae_label[i]]-z_train[i,:])) # L1 norm\n",
    "    loss_l2 += np.sum((vae_cluster_center[vae_label[i]]-z_train[i,:])**2) # L2 norm\n",
    "  loss_l1 /= n_train*n_window\n",
    "  loss_l2 /= n_train*n_window\n",
    "  vae_loss_l1_list.append(loss_l1)\n",
    "  vae_loss_l2_list.append(loss_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(10,3))\n",
    "axes[0].plot(range(2,10), vae_loss_l1_list)\n",
    "axes[0].set_xlabel(\"k\", fontsize=12)\n",
    "axes[0].set_ylabel(\"L1 loss\", fontsize=12)\n",
    "axes[1].plot(range(2,10), vae_loss_l2_list)\n",
    "axes[1].set_xlabel(\"k\", fontsize=12)\n",
    "axes[1].set_ylabel(\"L2 loss\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, 'vae_dfnc_kmeans_loss.png'), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(res_path, 'vae_loss_l1_list.npy'), vae_loss_l1_list)\n",
    "np.save(os.path.join(res_path, 'vae_loss_l2_list.npy'), vae_loss_l2_list)\n",
    "np.save(os.path.join(res_path, f'vae_label_state{n_state}.npy'), vae_label_list[n_state-2])\n",
    "np.save(os.path.join(res_path, f'vae_cluster_center_state{n_state}.npy'), vae_cluster_center_list[n_state-2])\n",
    "np.save(os.path.join(res_path, f'vae_all_state_state{n_state}.npy'), vae_all_state_list[n_state-2])\n",
    "\n",
    "# vae_loss_l1_list = np.load(os.path.join(res_path, 'vae_loss_l1_list.npy'))\n",
    "# vae_loss_l2_list = np.load(os.path.join(res_path, 'vae_loss_l2_list.npy'))\n",
    "# vae_kmeans_label = np.load(os.path.join(res_path, 'vae_label_state5.npy'))\n",
    "# vae_kmeans_cluster_center = np.load(os.path.join(res_path, 'vae_cluster_center_state5.npy'))\n",
    "# vae_kmeans_state = np.load(os.path.join(res_path, 'vae_all_state_state5.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_kmeans_state = vae_all_state_list[n_state-2]\n",
    "vae_kmeans_label = vae_label_list[n_state-2]\n",
    "vae_kmeans_cluster_center = vae_cluster_center_list[n_state-2]\n",
    "vae_num_sub_per_state, vae_ratio_sub_per_state = compute_sub_per_state(kmeans_label=vae_kmeans_label, n_pt=n_pt_train, n_window=n_window)\n",
    "vae_num_fnc_per_state, vae_ratio_fnc_per_state = compute_fnc_per_state(kmeans_label=vae_kmeans_label, n_pt=n_pt_train, n_window=n_window)\n",
    "\n",
    "vae_label_pt = vae_kmeans_label[:n_pt_train*n_window]\n",
    "vae_label_hc = vae_kmeans_label[n_pt_train*n_window:]\n",
    "vae_dfnc_data_train_pt = vae_dfnc_data_train[:n_pt_train*n_window,:]\n",
    "vae_dfnc_data_train_hc = vae_dfnc_data_train[n_pt_train*n_window:,:]\n",
    "\n",
    "vae_dfnc_state = np.zeros((3, n_state, 53, 53))\n",
    "for i in range(n_state):\n",
    "  cluster_median_1d_pt = np.median(vae_dfnc_data_train_pt[np.where(vae_label_pt == i)[0], :], axis=0)\n",
    "  cluster_median_1d_hc = np.median(vae_dfnc_data_train_hc[np.where(vae_label_hc == i)[0], :], axis=0)\n",
    "  vae_dfnc_state[0,i] = vector2matrix(cluster_median_1d_pt)\n",
    "  vae_dfnc_state[1,i] = vector2matrix(cluster_median_1d_hc)\n",
    "  vae_dfnc_state[2,i] = vae_dfnc_state[0,i] - vae_dfnc_state[1,i]\n",
    "\n",
    "# sort dFNC states by similarity between original and generated dFNC states\n",
    "corr = np.zeros((2, n_state, n_state))\n",
    "for i in range(n_state):\n",
    "  for j in range(n_state):\n",
    "    for k in range(2):\n",
    "      corr[k,i,j] = np.corrcoef((dfnc_state[k,i,:].flatten(), vae_dfnc_state[k,j,:].flatten()))[0,1]\n",
    "vae_sorted_state_ind = np.argmax(corr[0], axis=1)\n",
    "\n",
    "vae_unique_sorted_state_ind = find_unique_ind(vae_sorted_state_ind, corr, vae_ratio_fnc_per_state)\n",
    "vae_ratio_fnc_per_state_sorted = vae_ratio_fnc_per_state[:, vae_unique_sorted_state_ind]\n",
    "\n",
    "print(vae_num_sub_per_state)\n",
    "print(vae_ratio_sub_per_state)\n",
    "print(vae_num_fnc_per_state)\n",
    "print(vae_ratio_fnc_per_state)\n",
    "print(vae_unique_sorted_state_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_state = np.zeros((2, n_state))\n",
    "vae_dfnc_state_sorted = np.zeros((3, n_state, 53, 53))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=n_state, figsize=(5*n_state, 5*3))\n",
    "\n",
    "for i, j in enumerate(np.arange(n_state)[vae_unique_sorted_state_ind]):\n",
    "  state_pt = vae_dfnc_data_train_pt[np.where(vae_label_pt == j)[0], :]\n",
    "  state_hc = vae_dfnc_data_train_hc[np.where(vae_label_hc == j)[0], :]\n",
    "  stat, pvalue = stats.ttest_ind(a=state_pt, b=state_hc, equal_var=True)\n",
    "  pvalue_map = vector2matrix(pvalue)\n",
    "  pvalue_mask = pvalue_map <= (0.05/len(pvalue))\n",
    "  upper_triangle_mask = np.triu(np.ones_like(pvalue_mask)).astype(bool)\n",
    "  pvalue_mask[upper_triangle_mask] = 1\n",
    "  cluster_median_1d_pt = np.median(state_pt, axis=0)\n",
    "  cluster_median_1d_hc = np.median(state_hc, axis=0)\n",
    "  vae_dfnc_state_sorted[0,i] = vector2matrix(cluster_median_1d_pt)\n",
    "  vae_dfnc_state_sorted[1,i] = vector2matrix(cluster_median_1d_hc)\n",
    "  vae_dfnc_state_sorted[2,i] = vae_dfnc_state_sorted[0,i] - vae_dfnc_state_sorted[1,i]\n",
    "\n",
    "  if i == 0:\n",
    "    show_xticks = True\n",
    "  else:\n",
    "    show_xticks = False\n",
    "\n",
    "  plot_fnc(vae_dfnc_state_sorted[0,i], axes[0,i], f\"{round(vae_ratio_fnc_per_state_sorted[0,i]*100,1)}% ASD\\n{round(vae_ratio_fnc_per_state_sorted[1,i]*100,1)}% CTR\", show_xticks=show_xticks)\n",
    "  plot_fnc(vae_dfnc_state_sorted[1,i], axes[1,i], show_xticks=show_xticks)\n",
    "  plot_fnc(vae_dfnc_state_sorted[2,i] * pvalue_mask * 2, axes[2,i], show_xticks=show_xticks)\n",
    "\n",
    "  corr_state[0,i] = np.corrcoef((dfnc_state[0,i,:].flatten(), vae_dfnc_state_sorted[0,i,:].flatten()))[0,1]\n",
    "  corr_state[1,i] = np.corrcoef((dfnc_state[1,i,:].flatten(), vae_dfnc_state_sorted[1,i,:].flatten()))[0,1]\n",
    "  print(corr_state[0,i], corr_state[1,i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, f'vae_dfnc_kmeans_{n_state}states_pt_hc_pt-hc_sorted.png'), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=n_state, figsize=(5*n_state, 5))\n",
    "\n",
    "for i, j in enumerate(np.arange(n_state)[vae_unique_sorted_state_ind]):\n",
    "  state = vae_dfnc_data_train[np.where(vae_kmeans_label==j)[0],:]\n",
    "  state_median_1d = np.median(state, axis=0)\n",
    "  state_median_2d = vector2matrix(state_median_1d)\n",
    "  plot_fnc(state_median_2d, axes[i], f\"State {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, f'vae_dfnc_kmeans{n_state}states_pt_sorted.png'), bbox_inches='tight', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_dwell_time = vae_num_fnc_per_state / vae_num_sub_per_state\n",
    "vae_dwell_time_sorted = vae_dwell_time[:, vae_unique_sorted_state_ind]\n",
    "\n",
    "vae_kmeans_label_2d = vae_kmeans_label.reshape((n_train, n_window))\n",
    "vae_dwell_state_mean_pt, vae_dwell_state_ste_pt, vae_dwell_state_mean_hc, vae_dwell_state_ste_hc, vae_dwell_state_pvalue = compute_dwell_state(vae_kmeans_label_2d, vae_unique_sorted_state_ind, n_pt_train, n_hc_train)\n",
    "vae_transition_matrix_pt, vae_transition_matrix_hc, vae_transition_matrix, vae_transition_matrix_pvalue = compute_transition_matrix(vae_kmeans_label_2d, vae_unique_sorted_state_ind, n_pt_train)\n",
    "\n",
    "np.save(os.path.join(res_path, 'vae_dwell_time.npy'), vae_dwell_time_sorted)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_pvalue.npy'), vae_dwell_state_pvalue)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_mean_pt.npy'), vae_dwell_state_mean_pt)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_ste_pt.npy'), vae_dwell_state_ste_pt)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_mean_hc.npy'), vae_dwell_state_mean_hc)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_ste_hc.npy'), vae_dwell_state_ste_hc)\n",
    "np.save(os.path.join(res_path, 'vae_transition_matrix_pt.npy'), vae_transition_matrix_pt)\n",
    "np.save(os.path.join(res_path, 'vae_transition_matrix_hc.npy'), vae_transition_matrix_hc)\n",
    "np.save(os.path.join(res_path, 'vae_sorted_state_ind.npy'), vae_unique_sorted_state_ind)\n",
    "np.save(os.path.join(res_path, 'vae_kmeans_cluster_center.npy'), vae_kmeans_cluster_center)\n",
    "np.save(os.path.join(res_path, 'vae_kmeans_label.npy'), vae_kmeans_label)\n",
    "np.save(os.path.join(res_path, 'vae_transition_matrix.npy'), vae_transition_matrix)\n",
    "np.save(os.path.join(res_path, 'vae_transition_matrix_pvalue.npy'), vae_transition_matrix_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_dfnc_data_test = np.zeros(dfnc_data_test_2d.shape)\n",
    "for i in range(dfnc_data_test_2d.shape[0]):\n",
    "  vae_z = torch.Tensor([[z_test[i,0], z_test[i,1]]])\n",
    "  vae_dfnc_data_test[i,:] = np.squeeze(model.decode(vae_z).detach().numpy())\n",
    "np.save(os.path.join(res_path, 'vae_dfnc_data_test.npy'), vae_dfnc_data_test)\n",
    "\n",
    "# vae_dfnc_data_test = np.load(os.path.join(res_path, 'vae_dfnc_data_test.npy'))\n",
    "# vae_kmeans_label_test = np.load(os.path.join(res_path, 'vae_kmeans_label_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = vae_kmeans_list[n_state-2]\n",
    "vae_kmeans_label_test = kmeans.predict(z_test)\n",
    "\n",
    "vae_num_sub_per_state_test, vae_ratio_sub_per_state_test = compute_sub_per_state(kmeans_label=vae_kmeans_label_test, n_pt=n_pt_test, n_window=n_window)\n",
    "vae_num_fnc_per_state_test, vae_ratio_fnc_per_state_test = compute_fnc_per_state(kmeans_label=vae_kmeans_label_test, n_pt=n_pt_test, n_window=n_window)\n",
    "\n",
    "vae_label_pt_test = vae_kmeans_label_test[:n_pt_test*n_window]\n",
    "vae_label_hc_test = vae_kmeans_label_test[n_pt_test*n_window:]\n",
    "vae_dfnc_data_test_pt = vae_dfnc_data_test[:n_pt_test*n_window,:]\n",
    "vae_dfnc_data_test_hc = vae_dfnc_data_test[n_pt_test*n_window:,:]\n",
    "\n",
    "vae_dfnc_state_test = np.zeros((3, n_state, 53, 53))\n",
    "for i in range(n_state):\n",
    "  cluster_median_1d_pt = np.median(vae_dfnc_data_test_pt[np.where(vae_label_pt_test == i)[0], :], axis=0)\n",
    "  cluster_median_1d_hc = np.median(vae_dfnc_data_test_hc[np.where(vae_label_hc_test == i)[0], :], axis=0)\n",
    "  vae_dfnc_state_test[0,i] = vector2matrix(cluster_median_1d_pt)\n",
    "  vae_dfnc_state_test[1,i] = vector2matrix(cluster_median_1d_hc)\n",
    "  vae_dfnc_state_test[2,i] = vae_dfnc_state_test[0,i] - vae_dfnc_state_test[1,i]\n",
    "\n",
    "corr_test = np.zeros((2, n_state, n_state))\n",
    "for i in range(n_state):\n",
    "  for j in range(n_state):\n",
    "    for k in range(2):\n",
    "      corr_test[k,i,j] = np.corrcoef((dfnc_state_test[k,i,:].flatten(), vae_dfnc_state_test[k,j,:].flatten()))[0,1]\n",
    "\n",
    "vae_sorted_state_ind_test = np.argmax(corr_test[0], axis=1)\n",
    "vae_unique_sorted_state_ind_test = find_unique_ind(vae_sorted_state_ind_test, corr_test, vae_ratio_fnc_per_state_test)\n",
    "vae_ratio_fnc_per_state_sorted_test = vae_ratio_fnc_per_state_test[:, vae_unique_sorted_state_ind_test]\n",
    "print(vae_unique_sorted_state_ind_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_corr_state_test = np.zeros((2, n_state))\n",
    "vae_dfnc_state_test = np.zeros((3, n_state, 53, 53))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=n_state, figsize=(5*n_state, 5*3))\n",
    "\n",
    "for i, j in enumerate(np.arange(n_state)[vae_unique_sorted_state_ind_test]):\n",
    "  state_pt = vae_dfnc_data_test_pt[np.where(vae_label_pt_test == j)[0], :]\n",
    "  state_hc = vae_dfnc_data_test_hc[np.where(vae_label_hc_test == j)[0], :]\n",
    "\n",
    "  stat, pvalue = stats.ttest_ind(a=state_pt, b=state_hc, equal_var=True)\n",
    "  pvalue_map = vector2matrix(pvalue)\n",
    "  pvalue_mask = pvalue_map <= (0.05/len(pvalue))\n",
    "  upper_triangle_mask = np.triu(np.ones_like(pvalue_mask)).astype(bool)\n",
    "  pvalue_mask[upper_triangle_mask] = 1\n",
    "\n",
    "  cluster_median_1d_pt = np.median(state_pt, axis=0)\n",
    "  cluster_median_1d_hc = np.median(state_hc, axis=0)\n",
    "\n",
    "  vae_dfnc_state_test[0,i] = vector2matrix(cluster_median_1d_pt)\n",
    "  vae_dfnc_state_test[1,i] = vector2matrix(cluster_median_1d_hc)\n",
    "  vae_dfnc_state_test[2,i] = vae_dfnc_state_test[0,i] - vae_dfnc_state_test[1,i]\n",
    "\n",
    "  if i == 0:\n",
    "    show_xticks = True\n",
    "  else:\n",
    "    show_xticks = False\n",
    "\n",
    "  plot_fnc(vae_dfnc_state_test[0,i], axes[0,i], f\"{round(vae_ratio_fnc_per_state_sorted_test[0,i]*100,1)}% ASD\\n{round(vae_ratio_fnc_per_state_sorted_test[1,i]*100,1)}% CTR\", show_xticks=show_xticks)\n",
    "  plot_fnc(vae_dfnc_state_test[1,i], axes[1,i], show_xticks=show_xticks)\n",
    "  plot_fnc(vae_dfnc_state_test[2,i] * pvalue_mask * 2, axes[2,i], show_xticks=show_xticks)\n",
    "\n",
    "  vae_corr_state_test[0,i] = np.corrcoef((dfnc_state_test[0,i,:].flatten(), vae_dfnc_state_test[0,i,:].flatten()))[0,1]\n",
    "  vae_corr_state_test[1,i] = np.corrcoef((dfnc_state_test[1,i,:].flatten(), vae_dfnc_state_test[1,i,:].flatten()))[0,1]\n",
    "  print(vae_corr_state_test[0,i], vae_corr_state_test[1,i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_path, f'vae_dfnc_kmeans_{n_state}states_pt_hc_pt-hc_sorted_test.png'), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_dwell_time_test = vae_num_fnc_per_state_test / vae_num_sub_per_state_test\n",
    "vae_dwell_time_sorted_test = vae_dwell_time_test[:, vae_unique_sorted_state_ind_test]\n",
    "\n",
    "vae_kmeans_label_2d_test = vae_kmeans_label_test.reshape((n_test, n_window))\n",
    "vae_dwell_state_mean_pt_test, vae_dwell_state_ste_pt_test, vae_dwell_state_mean_hc_test, vae_dwell_state_ste_hc_test, vae_dwell_state_pvalue_test = compute_dwell_state(vae_kmeans_label_2d_test, vae_unique_sorted_state_ind_test, n_pt_test, n_hc_test)\n",
    "vae_transition_matrix_pt_test, vae_transition_matrix_hc_test, vae_transition_matrix_test, vae_transition_matrix_pvalue_test = compute_transition_matrix(vae_kmeans_label_2d_test, vae_unique_sorted_state_ind_test, n_pt_test)\n",
    "\n",
    "np.save(os.path.join(res_path, 'vae_dwell_time_test.npy'), vae_dwell_time_sorted_test)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_pvalue_test.npy'), vae_dwell_state_pvalue_test)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_mean_pt_test.npy'), vae_dwell_state_mean_pt_test)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_ste_pt_test.npy'), vae_dwell_state_ste_pt_test)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_mean_hc_test.npy'), vae_dwell_state_mean_hc_test)\n",
    "np.save(os.path.join(res_path, 'vae_dwell_state_ste_hc_test.npy'), vae_dwell_state_ste_hc_test)\n",
    "np.save(os.path.join(res_path, 'vae_transition_matrix_pt_test.npy'), vae_transition_matrix_pt_test)\n",
    "np.save(os.path.join(res_path, 'vae_transition_matrix_hc_test.npy'), vae_transition_matrix_hc_test)\n",
    "np.save(os.path.join(res_path, 'vae_sorted_state_ind_test.npy'), vae_unique_sorted_state_ind_test)\n",
    "np.save(os.path.join(res_path, 'vae_kmeans_label_test.npy'), vae_kmeans_label_test)\n",
    "np.save(os.path.join(res_path, 'vae_transition_matrix_test.npy'), vae_transition_matrix_test)\n",
    "np.save(os.path.join(res_path, 'vae_transition_matrix_pvalue_test.npy'), vae_transition_matrix_pvalue_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnc_corr_matrix_train = np.corrcoef(vae_dfnc_data_train, dfnc_data_train_2d)\n",
    "dfnc_corr_vector_train = np.diag(dfnc_corr_matrix_train[n_train*n_window:,:n_train*n_window])\n",
    "dfnc_corr_matrix_test = np.corrcoef(vae_dfnc_data_test, dfnc_data_test_2d)\n",
    "dfnc_corr_vector_test = np.diag(dfnc_corr_matrix_test[n_test*n_window:,:n_test*n_window])\n",
    "\n",
    "print(np.mean(dfnc_corr_vector_train))\n",
    "print(np.mean(dfnc_corr_vector_test))\n",
    "\n",
    "np.save(os.path.join(res_path, 'dfnc_corr_train.npy'), dfnc_corr_vector_train)\n",
    "np.save(os.path.join(res_path, 'dfnc_corr_test.npy'), dfnc_corr_vector_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
